{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b253bd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "340110a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Lock to pre-4.excalidraw as the source\n",
    "file_path = '/Users/selen/Desktop/projects/temp/pre-4.excalidraw'\n",
    "assert os.path.exists(file_path), f'File not found: {file_path}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1ab4951e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54, 55, 10)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    excalidraw_data = json.load(f)\n",
    "\n",
    "# Split elements by types we care about\n",
    "all_elements = excalidraw_data.get('elements', [])\n",
    "rects = [e for e in all_elements if e.get('type') == 'rectangle']\n",
    "texts = [e for e in all_elements if e.get('type') == 'text']\n",
    "arrows = [e for e in all_elements if e.get('type') == 'arrow']\n",
    "\n",
    "len(rects), len(texts), len(arrows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822b8b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "573cf4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rectangles (boxes): 54\n",
      "Total text elements: 55\n",
      "Total arrows: 10\n",
      "\n",
      "Texts with containerId: 55\n",
      "Texts with containerId pointing to rectangles: 54\n",
      "Rectangles with text via containerId: 54\n",
      "\n",
      "Texts WITHOUT containerId: 0\n",
      "  (These are: cluster labels, arrow labels, or orphaned texts)\n",
      "\n",
      "Rectangles WITHOUT text via containerId: 0\n"
     ]
    }
   ],
   "source": [
    "# Diagnostic: Check containerId coverage\n",
    "id_to_element = {e['id']: e for e in all_elements}\n",
    "\n",
    "print(f\"Total rectangles (boxes): {len(rects)}\")\n",
    "print(f\"Total text elements: {len(texts)}\")\n",
    "print(f\"Total arrows: {len(arrows)}\")\n",
    "print()\n",
    "\n",
    "# Check how many texts have containerId\n",
    "texts_with_container = [t for t in texts if t.get('containerId')]\n",
    "print(f\"Texts with containerId: {len(texts_with_container)}\")\n",
    "\n",
    "# Check how many of those containerIds point to rectangles\n",
    "texts_pointing_to_rects = [\n",
    "    t for t in texts_with_container \n",
    "    if t.get('containerId') in id_to_element \n",
    "    and id_to_element[t['containerId']].get('type') == 'rectangle'\n",
    "]\n",
    "print(f\"Texts with containerId pointing to rectangles: {len(texts_pointing_to_rects)}\")\n",
    "\n",
    "# Check how many rectangles have at least one text with containerId pointing to them\n",
    "rects_with_text_via_container = set(\n",
    "    t['containerId'] for t in texts_pointing_to_rects\n",
    ")\n",
    "print(f\"Rectangles with text via containerId: {len(rects_with_text_via_container)}\")\n",
    "print()\n",
    "\n",
    "# Check texts without containerId\n",
    "texts_without_container = [t for t in texts if not t.get('containerId')]\n",
    "print(f\"Texts WITHOUT containerId: {len(texts_without_container)}\")\n",
    "print(f\"  (These are: cluster labels, arrow labels, or orphaned texts)\")\n",
    "print()\n",
    "\n",
    "# Check rectangles without any text pointing to them via containerId\n",
    "rects_without_text_via_container = [\n",
    "    r for r in rects if r['id'] not in rects_with_text_via_container\n",
    "]\n",
    "print(f\"Rectangles WITHOUT text via containerId: {len(rects_without_text_via_container)}\")\n",
    "\n",
    "# Show a few examples of texts without containerId\n",
    "if texts_without_container:\n",
    "    print(\"\\nSample texts without containerId:\")\n",
    "    for t in texts_without_container[:5]:\n",
    "        print(f\"  - {t['id'][:20]}: {t.get('text', '')[:50]} (strokeColor: {t.get('strokeColor')})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0a8aaaf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrows with startBinding: 10\n",
      "Arrows with endBinding: 10\n",
      "Arrows with BOTH bindings: 10\n",
      "Arrows missing at least one binding: 0\n",
      "\n",
      "Sample arrow binding types:\n",
      "  startBinding -> rectangle (SvCbrmhMDuP39H-nlNWc)\n",
      "  endBinding -> rectangle (IHVKzfvL-5aIJIFxRFXS)\n"
     ]
    }
   ],
   "source": [
    "# Check arrow bindings\n",
    "arrows_with_start_binding = [a for a in arrows if a.get('startBinding')]\n",
    "arrows_with_end_binding = [a for a in arrows if a.get('endBinding')]\n",
    "arrows_with_both_bindings = [\n",
    "    a for a in arrows \n",
    "    if a.get('startBinding') and a.get('endBinding')\n",
    "]\n",
    "\n",
    "print(f\"Arrows with startBinding: {len(arrows_with_start_binding)}\")\n",
    "print(f\"Arrows with endBinding: {len(arrows_with_end_binding)}\")\n",
    "print(f\"Arrows with BOTH bindings: {len(arrows_with_both_bindings)}\")\n",
    "print(f\"Arrows missing at least one binding: {len(arrows) - len(arrows_with_both_bindings)}\")\n",
    "print()\n",
    "\n",
    "# Check if bindings point to rectangles\n",
    "if arrows_with_both_bindings:\n",
    "    sample_arrow = arrows_with_both_bindings[0]\n",
    "    start_id = sample_arrow.get('startBinding', {}).get('elementId')\n",
    "    end_id = sample_arrow.get('endBinding', {}).get('elementId')\n",
    "    start_type = id_to_element.get(start_id, {}).get('type') if start_id else None\n",
    "    end_type = id_to_element.get(end_id, {}).get('type') if end_id else None\n",
    "    print(f\"Sample arrow binding types:\")\n",
    "    print(f\"  startBinding -> {start_type} ({start_id[:20] if start_id else 'None'})\")\n",
    "    print(f\"  endBinding -> {end_type} ({end_id[:20] if end_id else 'None'})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7917819c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54, 54)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimized: containerId-only mapping for text→box (given 100% coverage)\n",
    "# Build rect_to_texts and text_to_rect using only containerId\n",
    "id_to_element = {e['id']: e for e in all_elements}\n",
    "\n",
    "text_to_rect = {}\n",
    "rect_to_texts = {r['id']: [] for r in rects}\n",
    "for t in texts:\n",
    "    cid = t.get('containerId')\n",
    "    # We assert it points to a rectangle per diagnostics\n",
    "    if cid and id_to_element.get(cid, {}).get('type') == 'rectangle':\n",
    "        text_to_rect[t['id']] = cid\n",
    "        rect_to_texts[cid].append(t['id'])\n",
    "    else:\n",
    "        text_to_rect[t['id']] = None  # safety fallback\n",
    "\n",
    "len(rect_to_texts), sum(len(v) for v in rect_to_texts.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "501bafef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimized: edges from arrow bindings first, geometry fallback only if missing\n",
    "\n",
    "def map_arrow_with_bindings(arrow: Dict) -> Tuple[Optional[str], Optional[str]]:\n",
    "    start_id = arrow.get('startBinding', {}).get('elementId') if arrow.get('startBinding') else None\n",
    "    end_id = arrow.get('endBinding', {}).get('elementId') if arrow.get('endBinding') else None\n",
    "    # Accept only rectangles\n",
    "    if start_id and id_to_element.get(start_id, {}).get('type') != 'rectangle':\n",
    "        start_id = None\n",
    "    if end_id and id_to_element.get(end_id, {}).get('type') != 'rectangle':\n",
    "        end_id = None\n",
    "    # If both found, return\n",
    "    if start_id or end_id:\n",
    "        return start_id, end_id\n",
    "    # Fallback to geometry (should not happen with your file, but safe)\n",
    "    return map_arrow_to_rects(arrow)\n",
    "\n",
    "edges = []\n",
    "for a in arrows:\n",
    "    src_id, dst_id = map_arrow_with_bindings(a)\n",
    "    # Optional label near midpoint (proximity; container linking to arrows is uncommon)\n",
    "    (sx, sy), (ex, ey) = arrow_endpoints_world(a)\n",
    "    midx, midy = (sx + ex) / 2.0, (sy + ey) / 2.0\n",
    "    label_text = None\n",
    "    label_text_id = None\n",
    "    near = nearest_text(midx, midy, max_distance=120.0)\n",
    "    if near is not None:\n",
    "        t_id = near['id']\n",
    "        t_rect = text_to_rect.get(t_id)\n",
    "        if t_rect not in (src_id, dst_id):\n",
    "            label_text = near.get('text')\n",
    "            label_text_id = t_id\n",
    "    edges.append({\n",
    "        'arrow_id': a['id'],\n",
    "        'src_rect_id': src_id,\n",
    "        'dst_rect_id': dst_id,\n",
    "        'label_text_id': label_text_id,\n",
    "        'label_text': label_text,\n",
    "    })\n",
    "\n",
    "len(edges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f871cc1a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'point_in_rect' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m member \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cr_id \u001b[38;5;129;01min\u001b[39;00m cluster_rect_ids:\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mpoint_in_rect\u001b[49m(cx, cy, id_to_element[cr_id]):\n\u001b[1;32m     37\u001b[0m         member \u001b[38;5;241m=\u001b[39m cr_id\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'point_in_rect' is not defined"
     ]
    }
   ],
   "source": [
    "# Optimized: cluster detection\n",
    "# - Cluster rectangles: dashed strokeStyle\n",
    "# - Cluster title: red text with containerId == cluster rect id (preferred), else geometric containment\n",
    "\n",
    "RED = '#e03131'\n",
    "\n",
    "cluster_rect_ids = [r['id'] for r in rects if r.get('strokeStyle') == 'dashed']\n",
    "\n",
    "rect_id_to_cluster_label = {}\n",
    "for cr_id in cluster_rect_ids:\n",
    "    # Prefer red texts whose containerId points to this cluster rect\n",
    "    label = None\n",
    "    for t in texts:\n",
    "        if t.get('strokeColor') == RED and t.get('containerId') == cr_id:\n",
    "            label = t['id']\n",
    "            break\n",
    "    if label is None:\n",
    "        # Fallback: geometric containment\n",
    "        cr = id_to_element[cr_id]\n",
    "        for t in texts:\n",
    "            if t.get('strokeColor') == RED:\n",
    "                cx = t.get('x', 0.0) + t.get('width', 0.0) / 2.0\n",
    "                cy = t.get('y', 0.0) + t.get('height', 0.0) / 2.0\n",
    "                if point_in_rect(cx, cy, cr):\n",
    "                    label = t['id']\n",
    "                    break\n",
    "    rect_id_to_cluster_label[cr_id] = label\n",
    "\n",
    "# Membership: rect center-in-cluster rect (geometry is appropriate here)\n",
    "rect_id_to_cluster_rect = {}\n",
    "for r in rects:\n",
    "    cx = r.get('x', 0.0) + r.get('width', 0.0) / 2.0\n",
    "    cy = r.get('y', 0.0) + r.get('height', 0.0) / 2.0\n",
    "    member = None\n",
    "    for cr_id in cluster_rect_ids:\n",
    "        if point_in_rect(cx, cy, id_to_element[cr_id]):\n",
    "            member = cr_id\n",
    "            break\n",
    "    rect_id_to_cluster_rect[r['id']] = member\n",
    "\n",
    "len(cluster_rect_ids), sum(1 for v in rect_id_to_cluster_rect.values() if v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d529a6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebuild nodes table with bindings-first logic\n",
    "rect_id_to_primary_text = {}\n",
    "for r in rects:\n",
    "    tids = rect_to_texts.get(r['id'], [])\n",
    "    # For cluster rects, avoid the red label as the primary node text\n",
    "    candidates = []\n",
    "    for t_id in tids:\n",
    "        t = id_to_element[t_id]\n",
    "        if r.get('strokeStyle') == 'dashed' and t.get('strokeColor') == RED:\n",
    "            continue\n",
    "        candidates.append(t)\n",
    "    pt = None\n",
    "    if candidates:\n",
    "        candidates.sort(key=lambda t: (t.get('fontSize') or 0), reverse=True)\n",
    "        pt = candidates[0]\n",
    "    rect_id_to_primary_text[r['id']] = pt\n",
    "\n",
    "nodes = []\n",
    "for r in rects:\n",
    "    pt = rect_id_to_primary_text.get(r['id'])\n",
    "    nodes.append({\n",
    "        'rect_id': r['id'],\n",
    "        'rect_is_cluster': r['id'] in cluster_rect_ids,\n",
    "        'text_id': pt['id'] if pt else None,\n",
    "        'text': pt.get('text') if pt else None,\n",
    "        'cluster_rect_id': rect_id_to_cluster_rect.get(r['id']),\n",
    "        'cluster_label_text_id': rect_id_to_cluster_label.get(rect_id_to_cluster_rect.get(r['id'])) if rect_id_to_cluster_rect.get(r['id']) else None,\n",
    "    })\n",
    "\n",
    "nodes_df = pd.DataFrame(nodes)\n",
    "nodes_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a60e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebuild edges table (bindings-first already applied above)\n",
    "edge_rows = []\n",
    "for e in edges:\n",
    "    src_r = e['src_rect_id']\n",
    "    dst_r = e['dst_rect_id']\n",
    "    if not src_r or not dst_r:\n",
    "        continue\n",
    "    src_t = rect_id_to_primary_text.get(src_r)\n",
    "    dst_t = rect_id_to_primary_text.get(dst_r)\n",
    "    edge_rows.append({\n",
    "        'arrow_id': e['arrow_id'],\n",
    "        'src_rect_id': src_r,\n",
    "        'src_text_id': src_t['id'] if src_t else None,\n",
    "        'src_text': src_t.get('text') if src_t else None,\n",
    "        'dst_rect_id': dst_r,\n",
    "        'dst_text_id': dst_t['id'] if dst_t else None,\n",
    "        'dst_text': dst_t.get('text') if dst_t else None,\n",
    "        'edge_label_text_id': e['label_text_id'],\n",
    "        'edge_label_text': e['label_text'],\n",
    "    })\n",
    "\n",
    "edges_df = pd.DataFrame(edge_rows)\n",
    "edges_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b5767f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebuild final graph_df and export\n",
    "cluster_rect_to_label_text = {\n",
    "    cr_id: (id_to_element[label_id]['text'] if label_id else None)\n",
    "    for cr_id, label_id in rect_id_to_cluster_label.items()\n",
    "}\n",
    "\n",
    "node_cluster_text = {\n",
    "    n['rect_id']: cluster_rect_to_label_text.get(n['cluster_rect_id']) if n['cluster_rect_id'] else None\n",
    "    for n in nodes\n",
    "}\n",
    "\n",
    "graph_rows = []\n",
    "for e in edge_rows:\n",
    "    graph_rows.append({\n",
    "        'from_rect_id': e['src_rect_id'],\n",
    "        'from_text_id': e['src_text_id'],\n",
    "        'from_text': e['src_text'],\n",
    "        'from_cluster_label': node_cluster_text.get(e['src_rect_id']),\n",
    "        'to_rect_id': e['dst_rect_id'],\n",
    "        'to_text_id': e['dst_text_id'],\n",
    "        'to_text': e['dst_text'],\n",
    "        'to_cluster_label': node_cluster_text.get(e['dst_rect_id']),\n",
    "        'edge_label_text': e['edge_label_text'],\n",
    "        'edge_label_text_id': e['edge_label_text_id'],\n",
    "        'arrow_id': e['arrow_id'],\n",
    "    })\n",
    "\n",
    "graph_df = pd.DataFrame(graph_rows)\n",
    "print(f\"Nodes: {len(nodes_df)} | Edges: {len(edges_df)} | Rows: {len(graph_df)}\")\n",
    "\n",
    "export_path = '/Users/selen/Desktop/projects/temp/graph.csv'\n",
    "graph_df.to_csv(export_path, index=False)\n",
    "print(f\"Exported: {export_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf8b7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved arrow label detection: prefer group linkage, fallback to distance-to-segment\n",
    "from math import hypot\n",
    "\n",
    "def shares_group(a: Dict, t: Dict) -> bool:\n",
    "    ag = set(a.get('groupIds') or [])\n",
    "    tg = set(t.get('groupIds') or [])\n",
    "    return len(ag & tg) > 0\n",
    "\n",
    "# Distance from a point to a line segment\n",
    "def point_segment_distance(px: float, py: float, x1: float, y1: float, x2: float, y2: float) -> float:\n",
    "    dx, dy = x2 - x1, y2 - y1\n",
    "    if dx == 0 and dy == 0:\n",
    "        return hypot(px - x1, py - y1)\n",
    "    t = ((px - x1) * dx + (py - y1) * dy) / (dx*dx + dy*dy)\n",
    "    t = max(0.0, min(1.0, t))\n",
    "    projx, projy = x1 + t*dx, y1 + t*dy\n",
    "    return hypot(px - projx, py - projy)\n",
    "\n",
    "# Build edges again with improved label detection\n",
    "new_edges = []\n",
    "for a in arrows:\n",
    "    src_id, dst_id = map_arrow_with_bindings(a)\n",
    "    (sx, sy), (ex, ey) = arrow_endpoints_world(a)\n",
    "\n",
    "    # Candidate labels by shared group first\n",
    "    group_candidates = []\n",
    "    for t in texts:\n",
    "        if t.get('strokeColor') == RED:\n",
    "            continue\n",
    "        if shares_group(a, t):\n",
    "            tr = text_to_rect.get(t['id'])\n",
    "            if tr not in (src_id, dst_id):\n",
    "                d = point_segment_distance(t.get('x',0)+t.get('width',0)/2, t.get('y',0)+t.get('height',0)/2, sx, sy, ex, ey)\n",
    "                group_candidates.append((d, t))\n",
    "    label_text = None\n",
    "    label_text_id = None\n",
    "    if group_candidates:\n",
    "        group_candidates.sort(key=lambda x: x[0])\n",
    "        label_text = group_candidates[0][1].get('text')\n",
    "        label_text_id = group_candidates[0][1]['id']\n",
    "    else:\n",
    "        # Fallback: nearest text to segment, excluding node texts and cluster titles\n",
    "        best = (float('inf'), None)\n",
    "        for t in texts:\n",
    "            if t.get('strokeColor') == RED:\n",
    "                continue\n",
    "            tr = text_to_rect.get(t['id'])\n",
    "            if tr in (src_id, dst_id):\n",
    "                continue\n",
    "            d = point_segment_distance(t.get('x',0)+t.get('width',0)/2, t.get('y',0)+t.get('height',0)/2, sx, sy, ex, ey)\n",
    "            if d < best[0]:\n",
    "                best = (d, t)\n",
    "        # Threshold to avoid spurious picks; tune if needed\n",
    "        if best[1] is not None and best[0] <= 120.0:\n",
    "            label_text = best[1].get('text')\n",
    "            label_text_id = best[1]['id']\n",
    "\n",
    "    new_edges.append({\n",
    "        'arrow_id': a['id'],\n",
    "        'src_rect_id': src_id,\n",
    "        'dst_rect_id': dst_id,\n",
    "        'label_text_id': label_text_id,\n",
    "        'label_text': label_text,\n",
    "    })\n",
    "\n",
    "edges = new_edges\n",
    "print(f\"Edges total: {len(edges)} | With labels: {sum(1 for e in edges if e['label_text'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b53ccd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebuild edges_df and graph_df with updated labels\n",
    "edge_rows = []\n",
    "for e in edges:\n",
    "    src_r = e['src_rect_id']\n",
    "    dst_r = e['dst_rect_id']\n",
    "    if not src_r or not dst_r:\n",
    "        continue\n",
    "    src_t = rect_id_to_primary_text.get(src_r)\n",
    "    dst_t = rect_id_to_primary_text.get(dst_r)\n",
    "    edge_rows.append({\n",
    "        'arrow_id': e['arrow_id'],\n",
    "        'src_rect_id': src_r,\n",
    "        'src_text_id': src_t['id'] if src_t else None,\n",
    "        'src_text': src_t.get('text') if src_t else None,\n",
    "        'dst_rect_id': dst_r,\n",
    "        'dst_text_id': dst_t['id'] if dst_t else None,\n",
    "        'dst_text': dst_t.get('text') if dst_t else None,\n",
    "        'edge_label_text_id': e['label_text_id'],\n",
    "        'edge_label_text': e['label_text'],\n",
    "    })\n",
    "\n",
    "edges_df = pd.DataFrame(edge_rows)\n",
    "\n",
    "cluster_rect_to_label_text = {\n",
    "    cr_id: (id_to_element[label_id]['text'] if label_id else None)\n",
    "    for cr_id, label_id in rect_id_to_cluster_label.items()\n",
    "}\n",
    "node_cluster_text = {\n",
    "    n['rect_id']: cluster_rect_to_label_text.get(n['cluster_rect_id']) if n['cluster_rect_id'] else None\n",
    "    for n in nodes\n",
    "}\n",
    "\n",
    "graph_rows = []\n",
    "for e in edge_rows:\n",
    "    graph_rows.append({\n",
    "        'from_rect_id': e['src_rect_id'],\n",
    "        'from_text_id': e['src_text_id'],\n",
    "        'from_text': e['src_text'],\n",
    "        'from_cluster_label': node_cluster_text.get(e['src_rect_id']),\n",
    "        'to_rect_id': e['dst_rect_id'],\n",
    "        'to_text_id': e['dst_text_id'],\n",
    "        'to_text': e['dst_text'],\n",
    "        'to_cluster_label': node_cluster_text.get(e['dst_rect_id']),\n",
    "        'edge_label_text': e['edge_label_text'],\n",
    "        'edge_label_text_id': e['edge_label_text_id'],\n",
    "        'arrow_id': e['arrow_id'],\n",
    "    })\n",
    "\n",
    "graph_df = pd.DataFrame(graph_rows)\n",
    "\n",
    "print(f\"Edges with labels: {len(edges_df[~edges_df['edge_label_text'].isna()])} / {len(edges_df)}\")\n",
    "export_path = '/Users/selen/Desktop/projects/temp/graph.csv'\n",
    "graph_df.to_csv(export_path, index=False)\n",
    "print(f\"Exported: {export_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2684c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bindings-first arrow label detection (containerId/boundElements), then fallback\n",
    "\n",
    "# Preindex texts by containerId (for arrow ids)\n",
    "texts_by_container: Dict[str, List[Dict]] = {}\n",
    "for t in texts:\n",
    "    cid = t.get('containerId')\n",
    "    if not cid:\n",
    "        continue\n",
    "    texts_by_container.setdefault(cid, []).append(t)\n",
    "\n",
    "# Helper to pick a single label from candidates (prefer larger font)\n",
    "def pick_label(cands: List[Dict]) -> Optional[Dict]:\n",
    "    if not cands:\n",
    "        return None\n",
    "    cands_sorted = sorted(cands, key=lambda t: (t.get('fontSize') or 0), reverse=True)\n",
    "    return cands_sorted[0]\n",
    "\n",
    "# Fallback helpers from previous cell\n",
    "from math import hypot\n",
    "\n",
    "def point_segment_distance(px: float, py: float, x1: float, y1: float, x2: float, y2: float) -> float:\n",
    "    dx, dy = x2 - x1, y2 - y1\n",
    "    if dx == 0 and dy == 0:\n",
    "        return hypot(px - x1, py - y1)\n",
    "    t = ((px - x1) * dx + (py - y1) * dy) / (dx*dx + dy*dy)\n",
    "    t = max(0.0, min(1.0, t))\n",
    "    projx, projy = x1 + t*dx, y1 + t*dy\n",
    "    return hypot(px - projx, py - projy)\n",
    "\n",
    "# Build edges with label detection priority:\n",
    "# 1) Any text where text.containerId == arrow.id (non-red)\n",
    "# 2) Any text listed in arrow.boundElements of type 'text' (non-red)\n",
    "# 3) Fallback: nearest-to-segment (non-red, not inside endpoint rects)\n",
    "new_edges: List[Dict] = []\n",
    "for a in arrows:\n",
    "    src_id, dst_id = map_arrow_with_bindings(a)\n",
    "    (sx, sy), (ex, ey) = arrow_endpoints_world(a)\n",
    "\n",
    "    label_text_obj: Optional[Dict] = None\n",
    "\n",
    "    # 1) containerId → arrow.id\n",
    "    cands = [t for t in texts_by_container.get(a['id'], []) if t.get('strokeColor') != RED]\n",
    "    picked = pick_label(cands)\n",
    "    if picked:\n",
    "        label_text_obj = picked\n",
    "    else:\n",
    "        # 2) arrow.boundElements → text ids\n",
    "        be_ids = []\n",
    "        for be in (a.get('boundElements') or []):\n",
    "            if be.get('type') == 'text' and be.get('id'):\n",
    "                be_ids.append(be['id'])\n",
    "        be_cands = [id_to_element[tid] for tid in be_ids if tid in id_to_element and id_to_element[tid].get('type') == 'text' and id_to_element[tid].get('strokeColor') != RED]\n",
    "        picked = pick_label(be_cands)\n",
    "        if picked:\n",
    "            label_text_obj = picked\n",
    "        else:\n",
    "            # 3) fallback proximity to segment, excluding node/cluster texts\n",
    "            best = (float('inf'), None)\n",
    "            for t in texts:\n",
    "                if t.get('strokeColor') == RED:\n",
    "                    continue\n",
    "                tr = text_to_rect.get(t['id'])\n",
    "                if tr in (src_id, dst_id):\n",
    "                    continue\n",
    "                cx = t.get('x', 0.0) + t.get('width', 0.0) / 2.0\n",
    "                cy = t.get('y', 0.0) + t.get('height', 0.0) / 2.0\n",
    "                d = point_segment_distance(cx, cy, sx, sy, ex, ey)\n",
    "                if d < best[0]:\n",
    "                    best = (d, t)\n",
    "            if best[1] is not None and best[0] <= 140.0:\n",
    "                label_text_obj = best[1]\n",
    "\n",
    "    new_edges.append({\n",
    "        'arrow_id': a['id'],\n",
    "        'src_rect_id': src_id,\n",
    "        'dst_rect_id': dst_id,\n",
    "        'label_text_id': (label_text_obj['id'] if label_text_obj else None),\n",
    "        'label_text': (label_text_obj.get('text') if label_text_obj else None),\n",
    "    })\n",
    "\n",
    "edges = new_edges\n",
    "print(f\"Edges total: {len(edges)} | With labels: {sum(1 for e in edges if e['label_text'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2ef702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebuild edges_df/graph_df once more and export\n",
    "edge_rows = []\n",
    "for e in edges:\n",
    "    src_r = e['src_rect_id']\n",
    "    dst_r = e['dst_rect_id']\n",
    "    if not src_r or not dst_r:\n",
    "        continue\n",
    "    src_t = rect_id_to_primary_text.get(src_r)\n",
    "    dst_t = rect_id_to_primary_text.get(dst_r)\n",
    "    edge_rows.append({\n",
    "        'arrow_id': e['arrow_id'],\n",
    "        'src_rect_id': src_r,\n",
    "        'src_text_id': src_t['id'] if src_t else None,\n",
    "        'src_text': src_t.get('text') if src_t else None,\n",
    "        'dst_rect_id': dst_r,\n",
    "        'dst_text_id': dst_t['id'] if dst_t else None,\n",
    "        'dst_text': dst_t.get('text') if dst_t else None,\n",
    "        'edge_label_text_id': e['label_text_id'],\n",
    "        'edge_label_text': e['label_text'],\n",
    "    })\n",
    "\n",
    "edges_df = pd.DataFrame(edge_rows)\n",
    "\n",
    "cluster_rect_to_label_text = {\n",
    "    cr_id: (id_to_element[label_id]['text'] if label_id else None)\n",
    "    for cr_id, label_id in rect_id_to_cluster_label.items()\n",
    "}\n",
    "node_cluster_text = {\n",
    "    n['rect_id']: cluster_rect_to_label_text.get(n['cluster_rect_id']) if n['cluster_rect_id'] else None\n",
    "    for n in nodes\n",
    "}\n",
    "\n",
    "graph_rows = []\n",
    "for e in edge_rows:\n",
    "    graph_rows.append({\n",
    "        'from_rect_id': e['src_rect_id'],\n",
    "        'from_text_id': e['src_text_id'],\n",
    "        'from_text': e['src_text'],\n",
    "        'from_cluster_label': node_cluster_text.get(e['src_rect_id']),\n",
    "        'to_rect_id': e['dst_rect_id'],\n",
    "        'to_text_id': e['dst_text_id'],\n",
    "        'to_text': e['dst_text'],\n",
    "        'to_cluster_label': node_cluster_text.get(e['dst_rect_id']),\n",
    "        'edge_label_text': e['edge_label_text'],\n",
    "        'edge_label_text_id': e['edge_label_text_id'],\n",
    "        'arrow_id': e['arrow_id'],\n",
    "    })\n",
    "\n",
    "graph_df = pd.DataFrame(graph_rows)\n",
    "\n",
    "print(f\"Edges with labels: {len(edges_df[~edges_df['edge_label_text'].isna()])} / {len(edges_df)}\")\n",
    "export_path = '/Users/selen/Desktop/projects/temp/graph.csv'\n",
    "graph_df.to_csv(export_path, index=False)\n",
    "print(f\"Exported: {export_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fb7b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9bce85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rect_bbox(rect: Dict) -> Tuple[float, float, float, float]:\n",
    "    return (\n",
    "        rect.get('x', 0.0),\n",
    "        rect.get('y', 0.0),\n",
    "        rect.get('x', 0.0) + rect.get('width', 0.0),\n",
    "        rect.get('y', 0.0) + rect.get('height', 0.0),\n",
    "    )\n",
    "\n",
    "# Basic point-in-rectangle test\n",
    "def point_in_rect(px: float, py: float, rect: Dict) -> bool:\n",
    "    x1, y1, x2, y2 = rect_bbox(rect)\n",
    "    return (x1 <= px <= x2) and (y1 <= py <= y2)\n",
    "\n",
    "# Test if a text element center lies within a rectangle\n",
    "# Text elements have x,y that refer to top-left and width,height\n",
    "# We'll use center point for a robust check\n",
    "\n",
    "def text_center(text: Dict) -> Tuple[float, float]:\n",
    "    return (\n",
    "        text.get('x', 0.0) + text.get('width', 0.0) / 2.0,\n",
    "        text.get('y', 0.0) + text.get('height', 0.0) / 2.0,\n",
    "    )\n",
    "\n",
    "# Identify cluster rectangles: dashed strokeStyle and find their red (#e03131) text\n",
    "\n",
    "def is_cluster_rect(rect: Dict) -> bool:\n",
    "    return rect.get('strokeStyle') == 'dashed'\n",
    "\n",
    "RED = '#e03131'\n",
    "\n",
    "# Build maps for quick lookup\n",
    "id_to_element: Dict[str, Dict] = {e['id']: e for e in all_elements}\n",
    "\n",
    "# Pre-index text by containerId (explicit link, if present)\n",
    "container_to_texts: Dict[str, List[Dict]] = {}\n",
    "for t in texts:\n",
    "    cid = t.get('containerId')\n",
    "    if cid:\n",
    "        container_to_texts.setdefault(cid, []).append(t)\n",
    "\n",
    "# Map each text to its containing rect (by containerId or geometry fallback)\n",
    "text_to_rect: Dict[str, Optional[str]] = {}\n",
    "rect_to_texts: Dict[str, List[str]] = {r['id']: [] for r in rects}\n",
    "\n",
    "for t in texts:\n",
    "    assigned_rect_id: Optional[str] = None\n",
    "    # 1) Prefer explicit container relationship\n",
    "    cid = t.get('containerId')\n",
    "    if cid and cid in id_to_element and id_to_element[cid].get('type') == 'rectangle':\n",
    "        assigned_rect_id = cid\n",
    "    else:\n",
    "        # 2) Fallback to geometry containment\n",
    "        cx, cy = text_center(t)\n",
    "        # pick the smallest rect that contains it (most specific)\n",
    "        candidates: List[Tuple[float, str]] = []\n",
    "        for r in rects:\n",
    "            if point_in_rect(cx, cy, r):\n",
    "                x1, y1, x2, y2 = rect_bbox(r)\n",
    "                area = (x2 - x1) * (y2 - y1)\n",
    "                candidates.append((area, r['id']))\n",
    "        if candidates:\n",
    "            candidates.sort()\n",
    "            assigned_rect_id = candidates[0][1]\n",
    "    text_to_rect[t['id']] = assigned_rect_id\n",
    "    if assigned_rect_id:\n",
    "        rect_to_texts[assigned_rect_id].append(t['id'])\n",
    "\n",
    "# Identify cluster rectangles and their labels (red text inside, not inside any other rect)\n",
    "cluster_rect_ids: List[str] = []\n",
    "rect_id_to_cluster_label: Dict[str, Optional[str]] = {}\n",
    "text_id_to_cluster: Dict[str, Optional[str]] = {}\n",
    "\n",
    "for r in rects:\n",
    "    if is_cluster_rect(r):\n",
    "        cluster_rect_ids.append(r['id'])\n",
    "\n",
    "# cluster label: a red text whose center is inside the dashed rect but not inside any other rect\n",
    "for r in rects:\n",
    "    if r['id'] in cluster_rect_ids:\n",
    "        x1, y1, x2, y2 = rect_bbox(r)\n",
    "        label_text_id: Optional[str] = None\n",
    "        for t in texts:\n",
    "            if t.get('strokeColor') == RED:\n",
    "                cx, cy = text_center(t)\n",
    "                if point_in_rect(cx, cy, r):\n",
    "                    # ensure not contained in a different (non-cluster) rect\n",
    "                    contained_elsewhere = False\n",
    "                    for r2 in rects:\n",
    "                        if r2['id'] == r['id']:\n",
    "                            continue\n",
    "                        if point_in_rect(cx, cy, r2):\n",
    "                            contained_elsewhere = True\n",
    "                            break\n",
    "                    if not contained_elsewhere:\n",
    "                        label_text_id = t['id']\n",
    "                        break\n",
    "        rect_id_to_cluster_label[r['id']] = label_text_id\n",
    "\n",
    "# For each rect, determine cluster membership by which dashed rect contains its center\n",
    "rect_id_to_cluster_rect: Dict[str, Optional[str]] = {}\n",
    "for r in rects:\n",
    "    cx = r.get('x', 0.0) + r.get('width', 0.0) / 2.0\n",
    "    cy = r.get('y', 0.0) + r.get('height', 0.0) / 2.0\n",
    "    member_cluster: Optional[str] = None\n",
    "    for cr_id in cluster_rect_ids:\n",
    "        cr = id_to_element[cr_id]\n",
    "        if point_in_rect(cx, cy, cr):\n",
    "            member_cluster = cr_id\n",
    "            break\n",
    "    rect_id_to_cluster_rect[r['id']] = member_cluster\n",
    "\n",
    "# Map each text element to its cluster via its rect's cluster\n",
    "for t_id, r_id in text_to_rect.items():\n",
    "    cluster_rect_id = rect_id_to_cluster_rect.get(r_id)\n",
    "    text_id_to_cluster[t_id] = cluster_rect_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5aea27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def element_center(el: Dict) -> Tuple[float, float]:\n",
    "    return (\n",
    "        el.get('x', 0.0) + el.get('width', 0.0) / 2.0,\n",
    "        el.get('y', 0.0) + el.get('height', 0.0) / 2.0,\n",
    "    )\n",
    "\n",
    "# Helper: find nearest text to a given point within a radius (used for arrow labels)\n",
    "def nearest_text(px: float, py: float, max_distance: float = 80.0) -> Optional[Dict]:\n",
    "    best = None\n",
    "    best_d2 = max_distance * max_distance\n",
    "    for t in texts:\n",
    "        cx, cy = text_center(t)\n",
    "        d2 = (cx - px) ** 2 + (cy - py) ** 2\n",
    "        if d2 <= best_d2:\n",
    "            best_d2 = d2\n",
    "            best = t\n",
    "    return best\n",
    "\n",
    "# Excalidraw arrow has points and optionally boundElements to/from\n",
    "# We'll determine tail (from) and head (to) boxes by proximity of arrow endpoints to rectangle borders\n",
    "\n",
    "def arrow_endpoints_world(arrow: Dict) -> Tuple[Tuple[float, float], Tuple[float, float]]:\n",
    "    # points are relative to arrow.x/y\n",
    "    pts = arrow.get('points', [])\n",
    "    if not pts:\n",
    "        return ((arrow.get('x', 0.0), arrow.get('y', 0.0)), (arrow.get('x', 0.0), arrow.get('y', 0.0)))\n",
    "    ax = arrow.get('x', 0.0)\n",
    "    ay = arrow.get('y', 0.0)\n",
    "    start = (ax + pts[0][0], ay + pts[0][1])\n",
    "    end = (ax + pts[-1][0], ay + pts[-1][1])\n",
    "    return start, end\n",
    "\n",
    "# Distance from a point to a rectangle border (0 if inside); also return rect id\n",
    "def point_rect_border_distance(px: float, py: float, rect: Dict) -> float:\n",
    "    x1, y1, x2, y2 = rect_bbox(rect)\n",
    "    # outside distance to edges\n",
    "    dx = max(x1 - px, 0.0, px - x2)\n",
    "    dy = max(y1 - py, 0.0, py - y2)\n",
    "    if dx == 0 and dy == 0:\n",
    "        # inside rect; return min distance to any edge\n",
    "        return min(px - x1, x2 - px, py - y1, y2 - py)\n",
    "    return (dx ** 2 + dy ** 2) ** 0.5\n",
    "\n",
    "# Map arrow to (from_rect_id, to_rect_id) by nearest rects to its endpoints\n",
    "\n",
    "def map_arrow_to_rects(arrow: Dict, search_radius: float = 120.0) -> Tuple[Optional[str], Optional[str]]:\n",
    "    (sx, sy), (ex, ey) = arrow_endpoints_world(arrow)\n",
    "    best_start = (float('inf'), None)\n",
    "    best_end = (float('inf'), None)\n",
    "    for r in rects:\n",
    "        ds = point_rect_border_distance(sx, sy, r)\n",
    "        de = point_rect_border_distance(ex, ey, r)\n",
    "        if ds < best_start[0]:\n",
    "            best_start = (ds, r['id'])\n",
    "        if de < best_end[0]:\n",
    "            best_end = (de, r['id'])\n",
    "    start_id = best_start[1] if best_start[0] <= search_radius else None\n",
    "    end_id = best_end[1] if best_end[0] <= search_radius else None\n",
    "    return start_id, end_id\n",
    "\n",
    "# Build edges list with optional labels\n",
    "edges: List[Dict] = []\n",
    "for a in arrows:\n",
    "    src_id, dst_id = map_arrow_to_rects(a)\n",
    "    # optional label text near arrow's midpoint\n",
    "    (sx, sy), (ex, ey) = arrow_endpoints_world(a)\n",
    "    midx, midy = (sx + ex) / 2.0, (sy + ey) / 2.0\n",
    "    label_text = None\n",
    "    label_text_id = None\n",
    "    near = nearest_text(midx, midy, max_distance=120.0)\n",
    "    if near is not None:\n",
    "        # avoid using node labels themselves as edge labels: only if it is not inside either endpoint rect\n",
    "        t_id = near['id']\n",
    "        t_rect = text_to_rect.get(t_id)\n",
    "        if t_rect not in (src_id, dst_id):\n",
    "            label_text = near.get('text')\n",
    "            label_text_id = t_id\n",
    "    edges.append({\n",
    "        'arrow_id': a['id'],\n",
    "        'src_rect_id': src_id,\n",
    "        'dst_rect_id': dst_id,\n",
    "        'label_text_id': label_text_id,\n",
    "        'label_text': label_text,\n",
    "    })\n",
    "\n",
    "len(edges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c03ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# Build node records keyed by rect id. Prefer the text that is inside that rect and not the cluster label.\n",
    "rect_id_to_primary_text: Dict[str, Optional[Dict]] = {}\n",
    "for r in rects:\n",
    "    text_ids = rect_to_texts.get(r['id'], [])\n",
    "    # exclude cluster label texts (red) if this rect itself is a cluster rect\n",
    "    candidates = []\n",
    "    for t_id in text_ids:\n",
    "        t = id_to_element[t_id]\n",
    "        if r.get('strokeStyle') == 'dashed' and t.get('strokeColor') == RED:\n",
    "            continue\n",
    "        candidates.append(t)\n",
    "    # pick the largest font or first as heuristic for node title\n",
    "    if candidates:\n",
    "        candidates.sort(key=lambda t: (t.get('fontSize') or 0), reverse=True)\n",
    "        rect_id_to_primary_text[r['id']] = candidates[0]\n",
    "    else:\n",
    "        rect_id_to_primary_text[r['id']] = None\n",
    "\n",
    "nodes: List[Dict] = []\n",
    "for r in rects:\n",
    "    rid = r['id']\n",
    "    pt = rect_id_to_primary_text.get(rid)\n",
    "    nodes.append({\n",
    "        'rect_id': rid,\n",
    "        'rect_is_cluster': rid in cluster_rect_ids,\n",
    "        'text_id': pt['id'] if pt else None,\n",
    "        'text': pt.get('text') if pt else None,\n",
    "        'cluster_rect_id': rect_id_to_cluster_rect.get(rid),\n",
    "        'cluster_label_text_id': rect_id_to_cluster_label.get(rect_id_to_cluster_rect.get(rid)) if rect_id_to_cluster_rect.get(rid) else None,\n",
    "    })\n",
    "\n",
    "nodes_df = pd.DataFrame(nodes)\n",
    "nodes_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d100218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build final edge table in terms of node texts and rect ids\n",
    "# Only keep edges where both endpoints map to valid rectangles\n",
    "edge_rows: List[Dict] = []\n",
    "for e in edges:\n",
    "    src_r = e['src_rect_id']\n",
    "    dst_r = e['dst_rect_id']\n",
    "    if not src_r or not dst_r:\n",
    "        continue\n",
    "    src_text = None\n",
    "    dst_text = None\n",
    "    src_t = rect_id_to_primary_text.get(src_r)\n",
    "    dst_t = rect_id_to_primary_text.get(dst_r)\n",
    "    if src_t is not None:\n",
    "        src_text = src_t.get('text')\n",
    "    if dst_t is not None:\n",
    "        dst_text = dst_t.get('text')\n",
    "    edge_rows.append({\n",
    "        'arrow_id': e['arrow_id'],\n",
    "        'src_rect_id': src_r,\n",
    "        'src_text_id': src_t['id'] if src_t else None,\n",
    "        'src_text': src_text,\n",
    "        'dst_rect_id': dst_r,\n",
    "        'dst_text_id': dst_t['id'] if dst_t else None,\n",
    "        'dst_text': dst_text,\n",
    "        'edge_label_text_id': e['label_text_id'],\n",
    "        'edge_label_text': e['label_text'],\n",
    "    })\n",
    "\n",
    "edges_df = pd.DataFrame(edge_rows)\n",
    "edges_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98059fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge node and edge tables into a single table as requested\n",
    "# For each node (text), produce outgoing edges to other nodes with directionality and cluster info\n",
    "\n",
    "# Helper maps for clusters\n",
    "cluster_rect_to_label_text: Dict[str, Optional[str]] = {\n",
    "    cr_id: (id_to_element[label_id]['text'] if label_id else None)\n",
    "    for cr_id, label_id in rect_id_to_cluster_label.items()\n",
    "}\n",
    "\n",
    "node_cluster_text: Dict[str, Optional[str]] = {}\n",
    "for n in nodes:\n",
    "    cr = n['cluster_rect_id']\n",
    "    node_cluster_text[n['rect_id']] = cluster_rect_to_label_text.get(cr) if cr else None\n",
    "\n",
    "rows: List[Dict] = []\n",
    "for e in edge_rows:\n",
    "    rows.append({\n",
    "        'from_rect_id': e['src_rect_id'],\n",
    "        'from_text_id': e['src_text_id'],\n",
    "        'from_text': e['src_text'],\n",
    "        'from_cluster_label': node_cluster_text.get(e['src_rect_id']),\n",
    "        'to_rect_id': e['dst_rect_id'],\n",
    "        'to_text_id': e['dst_text_id'],\n",
    "        'to_text': e['dst_text'],\n",
    "        'to_cluster_label': node_cluster_text.get(e['dst_rect_id']),\n",
    "        'edge_label_text': e['edge_label_text'],\n",
    "        'edge_label_text_id': e['edge_label_text_id'],\n",
    "        'arrow_id': e['arrow_id'],\n",
    "    })\n",
    "\n",
    "graph_df = pd.DataFrame(rows)\n",
    "\n",
    "# Present as requested: one table carrying visually encoded info\n",
    "graph_df.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401b6f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview and export helpers\n",
    "print(f\"Nodes: {len(nodes_df)} | Edges: {len(edges_df)} | Rows: {len(graph_df)}\")\n",
    "\n",
    "# Show a few problematic cases for QA\n",
    "missing_src = edges_df[edges_df['src_text'].isna()]\n",
    "missing_dst = edges_df[edges_df['dst_text'].isna()]\n",
    "print(f\"Edges missing src text: {len(missing_src)} | missing dst text: {len(missing_dst)}\")\n",
    "\n",
    "# Export to CSV if desired\n",
    "export_path = '/Users/selen/Desktop/projects/temp/graph.csv'\n",
    "graph_df.to_csv(export_path, index=False)\n",
    "print(f\"Exported: {export_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8c40310d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'export_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[43mexport_path\u001b[49m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# df = df.drop(columns=['arrow_id', 'from_rect_id', 'to_rect_id', 'from_text_id', 'to_text_id', 'to_cluster_label', 'edge_label_text_id'])\u001b[39;00m\n\u001b[1;32m      3\u001b[0m df[\u001b[38;5;241m~\u001b[39mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_label_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misna()]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'export_path' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(export_path)\n",
    "# df = df.drop(columns=['arrow_id', 'from_rect_id', 'to_rect_id', 'from_text_id', 'to_text_id', 'to_cluster_label', 'edge_label_text_id'])\n",
    "df[~df['edge_label_text'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa9c02d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f2a0579",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0c9537bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"graph.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "345d7879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_text</th>\n",
       "      <th>points_to</th>\n",
       "      <th>outgoing_labels</th>\n",
       "      <th>pointed_by</th>\n",
       "      <th>incoming_labels</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Patternalism, conformity and risk aversion lea...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>cluster 1 (the juice of the juiciest)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Scaling requires stability and structure, lead...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Companies are allergic to chaos']</td>\n",
       "      <td>[None]</td>\n",
       "      <td>cluster 1 (the juice of the juiciest)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FDEs may not actually see the unique \"problem\"...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>cluster 1 (the juice of the juiciest)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trust through replication is a competence\\nsho...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>cluster 1 (the juice of the juiciest)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adoption can fail due to product's dextrality,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>cluster 1 (the juice of the juiciest)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>real work is not in optimisation but optimisin...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>cluster 1 (the juice of the juiciest)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>scaled companies' flux is buried, with FDEs to...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>cluster 1 (the juice of the juiciest)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I am FDE for FDEs</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>cluster 1 (the juice of the juiciest)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Patternalism creates conformist structure but\\...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>cluster 1 (the juice of the juiciest)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"Companies should optimise around the problem\"</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>cluster 1 (the juice of the juiciest)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\"building right things → less prone to scaling...</td>\n",
       "      <td>['network effect, for a self-sustaining ecosys...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>cluster 1 (the juice of the juiciest)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>There is no right structure, because\\nstructur...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>cluster 1 (the juice of the juiciest)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>instead of boiling an ocean → build local warm...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>cluster 2 (less juice slightly, a bit more fou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dunbar's number concept is real:\\n\\ninnovation...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>cluster 2 (less juice slightly, a bit more fou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>How to put innovation into order? (big questio...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>cluster 2 (less juice slightly, a bit more fou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Order suppresses something you can't form in\\n...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>cluster 2 (less juice slightly, a bit more fou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>local optima traps</td>\n",
       "      <td>['need flux and perturbance ']</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>cluster 3 (other)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Legibility Enables Governance\\nJames C. Scott'...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>cluster 2 (less juice slightly, a bit more fou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>electrical engineering as a way to view all th...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>cluster 2 (less juice slightly, a bit more fou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>big question: so does the cold-blooded and\\nen...</td>\n",
       "      <td>['some thought: yes, but costs may be too high...</td>\n",
       "      <td>[None, None]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>cluster 3 (other)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>electrical engineering sometime fails to view\\...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>cluster 3 (other)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>#CONTEXT:Artist Colony vs Factory (Core\\nMecha...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>cluster 3 (other)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>FDEs increase the latent potential difference ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>cluster 2 (less juice slightly, a bit more fou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>FDEs increase medium conductivity to increase\\...</td>\n",
       "      <td>['or maybe its that they just build nice ecosy...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>cluster 2 (less juice slightly, a bit more fou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>FDEs increase medium conductivity to increase\\...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>cluster 2 (less juice slightly, a bit more fou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>FDEs are metabolism injections</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>cluster 2 (less juice slightly, a bit more fou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Path dependency strongly are like covalent\\nfo...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>cluster 2 (less juice slightly, a bit more fou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>translation is not just standing in a middle,\\...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>cluster 2 (less juice slightly, a bit more fou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>FDEs are compilers, they often have to operate...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>cluster 2 (less juice slightly, a bit more fou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>FDEs are compilers, not rewirers</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>cluster 2 (less juice slightly, a bit more fou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>FDEs must eventually learn two context grammar...</td>\n",
       "      <td>['sometimes, lack of bilinguality in internal\\...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>cluster 2 (less juice slightly, a bit more fou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>early co-development and more importantly\\neng...</td>\n",
       "      <td>['quote from interviewee :\"90% are there to\\nc...</td>\n",
       "      <td>['kinda related']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>cluster 2 (less juice slightly, a bit more fou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>quote from interviewee :\"90% are there to\\ncol...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['early co-development and more importantly\\ne...</td>\n",
       "      <td>['kinda related']</td>\n",
       "      <td>cluster 2 (less juice slightly, a bit more fou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>being a periphery is valuable because:\\n- you ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>cluster 2 (less juice slightly, a bit more fou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>companies hire FDEs as an injection or regular...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>cluster 1 (the juice of the juiciest)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Innovation is zero-sum, leading to incentive\\n...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>cluster 1 (the juice of the juiciest)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Important is optimisation that leads to\\noptim...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Currently, FDE lead to optimisation']</td>\n",
       "      <td>[None]</td>\n",
       "      <td>cluster 1 (the juice of the juiciest)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Currently, FDE lead to optimisation</td>\n",
       "      <td>['Important is optimisation that leads to\\nopt...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>cluster 1 (the juice of the juiciest)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Companies optimise by very same plan and\\ndete...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>cluster 1 (the juice of the juiciest)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Different metabolic rates (FDEs are to make\\ns...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>cluster 1 (the juice of the juiciest)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Companies are allergic to chaos</td>\n",
       "      <td>['Scaling requires stability and structure, le...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>cluster 1 (the juice of the juiciest)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>network effect, for a self-sustaining ecosyste...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['\"building right things → less prone to scali...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>cluster 1 (the juice of the juiciest)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>sometimes, lack of bilinguality in internal\\nt...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['FDEs must eventually learn two context gramm...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>cluster 2 (less juice slightly, a bit more fou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>or maybe its that they just build nice ecosyst...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['FDEs increase medium conductivity to increas...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>cluster 2 (less juice slightly, a bit more fou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>need flux and perturbance</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['local optima traps']</td>\n",
       "      <td>[None]</td>\n",
       "      <td>cluster 3 (other)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>#ADDIITONAL CONTEXT#\\n#TREAT IS LIKE A RAW UNS...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>cluster 4: BIG CONTEXTs ( to be used as a supp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>#ADDIITONAL CONTEXT#\\n#TREAT IS LIKE A RAW UNS...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>cluster 4: BIG CONTEXTs ( to be used as a supp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>some thought: yes, but costs may be too high, ...</td>\n",
       "      <td>['optimise the graph for optimisation!']</td>\n",
       "      <td>[None]</td>\n",
       "      <td>['big question: so does the cold-blooded and\\n...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>cluster 3 (other)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>optimise the graph for optimisation!</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['some thought: yes, but costs may be too high...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>cluster 3 (other)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>#context: Why broken companies can't do this:\\...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['big question: so does the cold-blooded and\\n...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>cluster 3 (other)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>cluster 3 (other)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>cluster 4: BIG CONTEXTs ( to be used as a supp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>cluster 2 (less juice slightly, a bit more fou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>cluster 1 (the juice of the juiciest)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            node_text  \\\n",
       "0   Patternalism, conformity and risk aversion lea...   \n",
       "1   Scaling requires stability and structure, lead...   \n",
       "2   FDEs may not actually see the unique \"problem\"...   \n",
       "3   Trust through replication is a competence\\nsho...   \n",
       "4   Adoption can fail due to product's dextrality,...   \n",
       "5   real work is not in optimisation but optimisin...   \n",
       "6   scaled companies' flux is buried, with FDEs to...   \n",
       "7                                   I am FDE for FDEs   \n",
       "8   Patternalism creates conformist structure but\\...   \n",
       "9      \"Companies should optimise around the problem\"   \n",
       "10  \"building right things → less prone to scaling...   \n",
       "11  There is no right structure, because\\nstructur...   \n",
       "12  instead of boiling an ocean → build local warm...   \n",
       "13  Dunbar's number concept is real:\\n\\ninnovation...   \n",
       "14  How to put innovation into order? (big questio...   \n",
       "15  Order suppresses something you can't form in\\n...   \n",
       "16                                 local optima traps   \n",
       "17  Legibility Enables Governance\\nJames C. Scott'...   \n",
       "18  electrical engineering as a way to view all th...   \n",
       "19  big question: so does the cold-blooded and\\nen...   \n",
       "20  electrical engineering sometime fails to view\\...   \n",
       "21  #CONTEXT:Artist Colony vs Factory (Core\\nMecha...   \n",
       "22  FDEs increase the latent potential difference ...   \n",
       "23  FDEs increase medium conductivity to increase\\...   \n",
       "24  FDEs increase medium conductivity to increase\\...   \n",
       "25                     FDEs are metabolism injections   \n",
       "26  Path dependency strongly are like covalent\\nfo...   \n",
       "27  translation is not just standing in a middle,\\...   \n",
       "28  FDEs are compilers, they often have to operate...   \n",
       "29                   FDEs are compilers, not rewirers   \n",
       "30  FDEs must eventually learn two context grammar...   \n",
       "31  early co-development and more importantly\\neng...   \n",
       "32  quote from interviewee :\"90% are there to\\ncol...   \n",
       "33  being a periphery is valuable because:\\n- you ...   \n",
       "34  companies hire FDEs as an injection or regular...   \n",
       "35  Innovation is zero-sum, leading to incentive\\n...   \n",
       "36  Important is optimisation that leads to\\noptim...   \n",
       "37                Currently, FDE lead to optimisation   \n",
       "38  Companies optimise by very same plan and\\ndete...   \n",
       "39  Different metabolic rates (FDEs are to make\\ns...   \n",
       "40                    Companies are allergic to chaos   \n",
       "41  network effect, for a self-sustaining ecosyste...   \n",
       "42  sometimes, lack of bilinguality in internal\\nt...   \n",
       "43  or maybe its that they just build nice ecosyst...   \n",
       "44                         need flux and perturbance    \n",
       "45  #ADDIITONAL CONTEXT#\\n#TREAT IS LIKE A RAW UNS...   \n",
       "46  #ADDIITONAL CONTEXT#\\n#TREAT IS LIKE A RAW UNS...   \n",
       "47  some thought: yes, but costs may be too high, ...   \n",
       "48               optimise the graph for optimisation!   \n",
       "49  #context: Why broken companies can't do this:\\...   \n",
       "50                                                NaN   \n",
       "51                                                NaN   \n",
       "52                                                NaN   \n",
       "53                                                NaN   \n",
       "\n",
       "                                            points_to    outgoing_labels  \\\n",
       "0                                                  []                 []   \n",
       "1                                                  []                 []   \n",
       "2                                                  []                 []   \n",
       "3                                                  []                 []   \n",
       "4                                                  []                 []   \n",
       "5                                                  []                 []   \n",
       "6                                                  []                 []   \n",
       "7                                                  []                 []   \n",
       "8                                                  []                 []   \n",
       "9                                                  []                 []   \n",
       "10  ['network effect, for a self-sustaining ecosys...             [None]   \n",
       "11                                                 []                 []   \n",
       "12                                                 []                 []   \n",
       "13                                                 []                 []   \n",
       "14                                                 []                 []   \n",
       "15                                                 []                 []   \n",
       "16                     ['need flux and perturbance ']             [None]   \n",
       "17                                                 []                 []   \n",
       "18                                                 []                 []   \n",
       "19  ['some thought: yes, but costs may be too high...       [None, None]   \n",
       "20                                                 []                 []   \n",
       "21                                                 []                 []   \n",
       "22                                                 []                 []   \n",
       "23  ['or maybe its that they just build nice ecosy...             [None]   \n",
       "24                                                 []                 []   \n",
       "25                                                 []                 []   \n",
       "26                                                 []                 []   \n",
       "27                                                 []                 []   \n",
       "28                                                 []                 []   \n",
       "29                                                 []                 []   \n",
       "30  ['sometimes, lack of bilinguality in internal\\...             [None]   \n",
       "31  ['quote from interviewee :\"90% are there to\\nc...  ['kinda related']   \n",
       "32                                                 []                 []   \n",
       "33                                                 []                 []   \n",
       "34                                                 []                 []   \n",
       "35                                                 []                 []   \n",
       "36                                                 []                 []   \n",
       "37  ['Important is optimisation that leads to\\nopt...             [None]   \n",
       "38                                                 []                 []   \n",
       "39                                                 []                 []   \n",
       "40  ['Scaling requires stability and structure, le...             [None]   \n",
       "41                                                 []                 []   \n",
       "42                                                 []                 []   \n",
       "43                                                 []                 []   \n",
       "44                                                 []                 []   \n",
       "45                                                 []                 []   \n",
       "46                                                 []                 []   \n",
       "47           ['optimise the graph for optimisation!']             [None]   \n",
       "48                                                 []                 []   \n",
       "49                                                 []                 []   \n",
       "50                                                 []                 []   \n",
       "51                                                 []                 []   \n",
       "52                                                 []                 []   \n",
       "53                                                 []                 []   \n",
       "\n",
       "                                           pointed_by    incoming_labels  \\\n",
       "0                                                  []                 []   \n",
       "1                 ['Companies are allergic to chaos']             [None]   \n",
       "2                                                  []                 []   \n",
       "3                                                  []                 []   \n",
       "4                                                  []                 []   \n",
       "5                                                  []                 []   \n",
       "6                                                  []                 []   \n",
       "7                                                  []                 []   \n",
       "8                                                  []                 []   \n",
       "9                                                  []                 []   \n",
       "10                                                 []                 []   \n",
       "11                                                 []                 []   \n",
       "12                                                 []                 []   \n",
       "13                                                 []                 []   \n",
       "14                                                 []                 []   \n",
       "15                                                 []                 []   \n",
       "16                                                 []                 []   \n",
       "17                                                 []                 []   \n",
       "18                                                 []                 []   \n",
       "19                                                 []                 []   \n",
       "20                                                 []                 []   \n",
       "21                                                 []                 []   \n",
       "22                                                 []                 []   \n",
       "23                                                 []                 []   \n",
       "24                                                 []                 []   \n",
       "25                                                 []                 []   \n",
       "26                                                 []                 []   \n",
       "27                                                 []                 []   \n",
       "28                                                 []                 []   \n",
       "29                                                 []                 []   \n",
       "30                                                 []                 []   \n",
       "31                                                 []                 []   \n",
       "32  ['early co-development and more importantly\\ne...  ['kinda related']   \n",
       "33                                                 []                 []   \n",
       "34                                                 []                 []   \n",
       "35                                                 []                 []   \n",
       "36            ['Currently, FDE lead to optimisation']             [None]   \n",
       "37                                                 []                 []   \n",
       "38                                                 []                 []   \n",
       "39                                                 []                 []   \n",
       "40                                                 []                 []   \n",
       "41  ['\"building right things → less prone to scali...             [None]   \n",
       "42  ['FDEs must eventually learn two context gramm...             [None]   \n",
       "43  ['FDEs increase medium conductivity to increas...             [None]   \n",
       "44                             ['local optima traps']             [None]   \n",
       "45                                                 []                 []   \n",
       "46                                                 []                 []   \n",
       "47  ['big question: so does the cold-blooded and\\n...             [None]   \n",
       "48  ['some thought: yes, but costs may be too high...             [None]   \n",
       "49  ['big question: so does the cold-blooded and\\n...             [None]   \n",
       "50                                                 []                 []   \n",
       "51                                                 []                 []   \n",
       "52                                                 []                 []   \n",
       "53                                                 []                 []   \n",
       "\n",
       "                                              cluster  \n",
       "0               cluster 1 (the juice of the juiciest)  \n",
       "1               cluster 1 (the juice of the juiciest)  \n",
       "2               cluster 1 (the juice of the juiciest)  \n",
       "3               cluster 1 (the juice of the juiciest)  \n",
       "4               cluster 1 (the juice of the juiciest)  \n",
       "5               cluster 1 (the juice of the juiciest)  \n",
       "6               cluster 1 (the juice of the juiciest)  \n",
       "7               cluster 1 (the juice of the juiciest)  \n",
       "8               cluster 1 (the juice of the juiciest)  \n",
       "9               cluster 1 (the juice of the juiciest)  \n",
       "10              cluster 1 (the juice of the juiciest)  \n",
       "11              cluster 1 (the juice of the juiciest)  \n",
       "12  cluster 2 (less juice slightly, a bit more fou...  \n",
       "13  cluster 2 (less juice slightly, a bit more fou...  \n",
       "14  cluster 2 (less juice slightly, a bit more fou...  \n",
       "15  cluster 2 (less juice slightly, a bit more fou...  \n",
       "16                                  cluster 3 (other)  \n",
       "17  cluster 2 (less juice slightly, a bit more fou...  \n",
       "18  cluster 2 (less juice slightly, a bit more fou...  \n",
       "19                                  cluster 3 (other)  \n",
       "20                                  cluster 3 (other)  \n",
       "21                                  cluster 3 (other)  \n",
       "22  cluster 2 (less juice slightly, a bit more fou...  \n",
       "23  cluster 2 (less juice slightly, a bit more fou...  \n",
       "24  cluster 2 (less juice slightly, a bit more fou...  \n",
       "25  cluster 2 (less juice slightly, a bit more fou...  \n",
       "26  cluster 2 (less juice slightly, a bit more fou...  \n",
       "27  cluster 2 (less juice slightly, a bit more fou...  \n",
       "28  cluster 2 (less juice slightly, a bit more fou...  \n",
       "29  cluster 2 (less juice slightly, a bit more fou...  \n",
       "30  cluster 2 (less juice slightly, a bit more fou...  \n",
       "31  cluster 2 (less juice slightly, a bit more fou...  \n",
       "32  cluster 2 (less juice slightly, a bit more fou...  \n",
       "33  cluster 2 (less juice slightly, a bit more fou...  \n",
       "34              cluster 1 (the juice of the juiciest)  \n",
       "35              cluster 1 (the juice of the juiciest)  \n",
       "36              cluster 1 (the juice of the juiciest)  \n",
       "37              cluster 1 (the juice of the juiciest)  \n",
       "38              cluster 1 (the juice of the juiciest)  \n",
       "39              cluster 1 (the juice of the juiciest)  \n",
       "40              cluster 1 (the juice of the juiciest)  \n",
       "41              cluster 1 (the juice of the juiciest)  \n",
       "42  cluster 2 (less juice slightly, a bit more fou...  \n",
       "43  cluster 2 (less juice slightly, a bit more fou...  \n",
       "44                                  cluster 3 (other)  \n",
       "45  cluster 4: BIG CONTEXTs ( to be used as a supp...  \n",
       "46  cluster 4: BIG CONTEXTs ( to be used as a supp...  \n",
       "47                                  cluster 3 (other)  \n",
       "48                                  cluster 3 (other)  \n",
       "49                                  cluster 3 (other)  \n",
       "50                                  cluster 3 (other)  \n",
       "51  cluster 4: BIG CONTEXTs ( to be used as a supp...  \n",
       "52  cluster 2 (less juice slightly, a bit more fou...  \n",
       "53              cluster 1 (the juice of the juiciest)  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop technical columns and rename for better readability\n",
    "df_clean = df.drop(\n",
    "    columns=[\n",
    "        'rect_id',\n",
    "        'rect_is_cluster', \n",
    "        'text_id',\n",
    "        'cluster_rect_id',\n",
    "        'cluster_label_text_id',\n",
    "        'outgoing_to_rect_ids',\n",
    "        'incoming_from_rect_ids'\n",
    "    ]\n",
    ").rename(\n",
    "    columns={\n",
    "        'text': 'node_text',\n",
    "        'cluster_label': 'cluster',\n",
    "        'outgoing_to_texts': 'points_to',\n",
    "        'outgoing_edge_labels': 'outgoing_labels',\n",
    "        'incoming_from_texts': 'pointed_by',\n",
    "        'incoming_edge_labels': 'incoming_labels'\n",
    "    }\n",
    ")\n",
    "\n",
    "df_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8e0bebf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markdown document saved to graph_clean.md\n",
      "Total nodes: 54\n",
      "\n",
      "First node preview:\n",
      "# Graph Nodes\n",
      "\n",
      "## Patternalism, conformity and risk aversion lead\n",
      "to reduced innovation\n",
      "\n",
      "**Cluster:** cluster 1 (the juice of the juiciest)\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "## Scaling requires stability and structure, leads\n",
      "to reduced innovation\n",
      "\n",
      "**Cluster:** cluster 1 (the juice of the juiciest)\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "## FDEs may not actually see the unique \"problem\"\n",
      "there is\n"
     ]
    }
   ],
   "source": [
    "# Render as markdown document (not table)\n",
    "lines = []\n",
    "lines.append(\"# Graph Nodes\\n\")\n",
    "\n",
    "for idx, row in df_clean.iterrows():\n",
    "    node_text = row['node_text']\n",
    "    cluster = row['cluster']\n",
    "    points_to = row['points_to'] if isinstance(row['points_to'], list) else []\n",
    "    outgoing_labels = row['outgoing_labels'] if isinstance(row['outgoing_labels'], list) else []\n",
    "    pointed_by = row['pointed_by'] if isinstance(row['pointed_by'], list) else []\n",
    "    incoming_labels = row['incoming_labels'] if isinstance(row['incoming_labels'], list) else []\n",
    "    \n",
    "    lines.append(f\"## {node_text}\\n\")\n",
    "    \n",
    "    if cluster:\n",
    "        lines.append(f\"**Cluster:** {cluster}\\n\")\n",
    "    \n",
    "    if points_to and any(points_to):\n",
    "        lines.append(f\"\\n**Points to:**\")\n",
    "        for i, target in enumerate(points_to):\n",
    "            label = outgoing_labels[i] if i < len(outgoing_labels) and outgoing_labels[i] else \"\"\n",
    "            if label:\n",
    "                lines.append(f\"- {target} *(label: {label})*\")\n",
    "            else:\n",
    "                lines.append(f\"- {target}\")\n",
    "    \n",
    "    if pointed_by and any(pointed_by):\n",
    "        lines.append(f\"\\n**Pointed by:**\")\n",
    "        for i, source in enumerate(pointed_by):\n",
    "            label = incoming_labels[i] if i < len(incoming_labels) and incoming_labels[i] else \"\"\n",
    "            if label:\n",
    "                lines.append(f\"- {source} *(label: {label})*\")\n",
    "            else:\n",
    "                lines.append(f\"- {source}\")\n",
    "    \n",
    "    lines.append(\"\\n---\\n\")\n",
    "\n",
    "markdown_output = \"\\n\".join(lines)\n",
    "\n",
    "# Save to file\n",
    "with open('graph_clean.md', 'w', encoding='utf-8') as f:\n",
    "    f.write(markdown_output)\n",
    "\n",
    "print(\"Markdown document saved to graph_clean.md\")\n",
    "print(f\"Total nodes: {len(df_clean)}\")\n",
    "print(\"\\nFirst node preview:\")\n",
    "print(\"\\n\".join(markdown_output.split(\"\\n\")[:20]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4925d910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markdown document saved to /Users/selen/Desktop/projects/temp/graph_doc.md\n",
      "Preview:\n",
      "# Graph Document\n",
      "\n",
      "## Cluster: cluster 1 (the juice of the juiciest)\n",
      "\n",
      "### Patternalism, conformity and risk aversion lead\n",
      "to reduced innovation\n",
      "\n",
      "### Scaling requires stability and structure, leads\n",
      "to reduced innovation\n",
      "\n",
      "- Incoming:\n",
      "  - ← Companies are allergic to chaos\n",
      "\n",
      "### FDEs may not actually see the unique \"problem\"\n",
      "there is\n",
      "\n",
      "### Trust through replication is a competence\n",
      "showrun\n",
      "\n",
      "### Adoption can fail due to product's dextrality,\n",
      "or worse ambisinistrality\n",
      "\n",
      "### real work is not in optimisation but optimising\n",
      "self-optimisation\n",
      "\n",
      "### scaled companies' flux is buried, with FDEs to\n",
      "excavate\n",
      "\n",
      "### I am FDE for FDEs\n",
      "\n",
      "### Patternalism creates conformist structure but\n",
      "\"unwills\" the latent potential\n",
      "\n",
      "### \"Companies should optimise around the problem\"\n",
      "\n",
      "### \"building right things → less prone to scaling\"\n",
      "\"building things right → leads to dexterity\"\n",
      "(only one side benefits)\n",
      "\n",
      "- Outgoing:\n",
      "  - → network effect, for a self-sustaining ecosystem,\n",
      "and true innovation, requires correct incentive\n",
      "mechanisms to join, and be part of the \"system\"\n",
      "\n",
      "### There is no right structure, because\n",
      "structurisation is a lossy algorithm and still\n",
      "only an illusion.\n",
      "\n",
      "### companies hire FDEs as an injection or regular\n",
      "vaccination\n",
      "\n",
      "### Innovation is zero-sum, leading to incentive\n",
      "absence to disrupt an equilibrium\n",
      "\n",
      "### Important is optimisation that leads to\n",
      "optimisation\n",
      "\n",
      "- Incoming:\n",
      "  - ← Currently, FDE lead to optimisation\n",
      "\n",
      "### Currently, FDE lead to optimisation\n",
      "\n",
      "- Outgoing:\n",
      "  - → Important is optimisation that leads to\n",
      "optimisation\n",
      "\n",
      "### Companies optimise by very same plan and\n",
      "determinism they need to remove, not how it\n",
      "should it be (more iteratively), leads to\n",
      "inability to adapt\n",
      "\n",
      "### Different metabolic rates (FDEs are to make\n",
      "sustainable value paths) but it is precisely\n",
      "what kills experimentation, leads to\n",
      "\n",
      "short-term optimisation ←→ long-term life\n",
      "tradeoff\n",
      "\n",
      "### Companies are allergic to chaos\n",
      "\n",
      "- Outgoing:\n",
      "  - → Scaling requires stability and structure, leads\n",
      "to reduced innovation\n",
      "\n",
      "### network effect, for a self-sustaining ecosystem,\n",
      "and true innovation, requires correct incentive\n",
      "mechanisms to join, and be part of the \"system\"\n",
      "\n",
      "- Incoming:\n",
      "  - ← \"building right things → less prone to scaling\"\n",
      "\"building things right → leads to dexterity\"\n",
      "(only one side benefits)\n",
      "\n",
      "### nan\n",
      "\n",
      "## Cluster: cluster 2 (less juice slightly, a bit more foundational)\n",
      "\n",
      "### instead of boiling an ocean → build local warm\n",
      "currents, to later unite their power for them to\n",
      "become golf-streams\n",
      "\n",
      "### Dunbar's number concept is real:\n",
      "\n",
      "innovation requires randomness, graph complexity\n",
      "becomes O(n^2), ←  cognitive complexity\n",
      "\n",
      "### How to put innovation into order? (big question)\n",
      "maybe find subcomponents of order that are\n",
      "allergic to innovation, and solve for the\n",
      "question accounting for that...?\n",
      "\n",
      "### Order suppresses something you can't form in\n",
      "words? lossy algorithm\n"
     ]
    }
   ],
   "source": [
    "# Build narrative markdown document (not a table)\n",
    "import ast\n",
    "from typing import List, Any\n",
    "\n",
    "# If df_clean came from CSV, lists may be strings; parse them\n",
    "list_cols = ['points_to', 'outgoing_labels', 'pointed_by', 'incoming_labels']\n",
    "for col in list_cols:\n",
    "    if col in df_clean.columns:\n",
    "        def _to_list(v: Any) -> List[str]:\n",
    "            if isinstance(v, list):\n",
    "                return v\n",
    "            if isinstance(v, str):\n",
    "                s = v.strip()\n",
    "                if s.startswith('[') and s.endswith(']'):\n",
    "                    try:\n",
    "                        parsed = ast.literal_eval(s)\n",
    "                        return parsed if isinstance(parsed, list) else []\n",
    "                    except Exception:\n",
    "                        return []\n",
    "                if s == '' or s.lower() == 'nan':\n",
    "                    return []\n",
    "                return [s]\n",
    "            return []\n",
    "        df_clean[col] = df_clean[col].apply(_to_list)\n",
    "\n",
    "# Fill cluster names\n",
    "df_clean['cluster'] = df_clean['cluster'].fillna('Unclustered')\n",
    "\n",
    "lines = []\n",
    "lines.append('# Graph Document')\n",
    "\n",
    "for cluster_name, g in df_clean.groupby('cluster'):\n",
    "    lines.append(f\"\\n## Cluster: {cluster_name}\")\n",
    "    for _, row in g.iterrows():\n",
    "        node_text = str(row.get('node_text') or '').strip()\n",
    "        lines.append(f\"\\n### {node_text}\")\n",
    "        # Outgoing\n",
    "        pts = row.get('points_to') or []\n",
    "        olabs = row.get('outgoing_labels') or []\n",
    "        if pts:\n",
    "            lines.append('\\n- Outgoing:')\n",
    "            for i, tgt in enumerate(pts):\n",
    "                lab = olabs[i] if i < len(olabs) else None\n",
    "                if lab and str(lab).strip():\n",
    "                    lines.append(f\"  - → {tgt} (label: {lab})\")\n",
    "                else:\n",
    "                    lines.append(f\"  - → {tgt}\")\n",
    "        # Incoming\n",
    "        srcs = row.get('pointed_by') or []\n",
    "        ilabs = row.get('incoming_labels') or []\n",
    "        if srcs:\n",
    "            lines.append('\\n- Incoming:')\n",
    "            for i, src in enumerate(srcs):\n",
    "                lab = ilabs[i] if i < len(ilabs) else None\n",
    "                if lab and str(lab).strip():\n",
    "                    lines.append(f\"  - ← {src} (label: {lab})\")\n",
    "                else:\n",
    "                    lines.append(f\"  - ← {src}\")\n",
    "\n",
    "md_path = '/Users/selen/Desktop/projects/temp/graph_doc.md'\n",
    "with open(md_path, 'w', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(lines))\n",
    "\n",
    "print(f\"Markdown document saved to {md_path}\")\n",
    "print('Preview:')\n",
    "print('\\n'.join(lines[:40]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "80c238b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv(\"graph_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fbca7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
